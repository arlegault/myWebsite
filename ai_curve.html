<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Where We Actually Are on the AI Curve</title>
    <link rel="stylesheet" href="mystyle.css">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NXF5ZY7FV4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-NXF5ZY7FV4');
</script>

</head>
<body>
<h1>Alex Legault</h1>
<ul style="list-style-type: none">
    <li><a href="about.html">About</a></li>
    <li><a href="writing.html">Writing</a></li>
    <li><a href="books.html">Books</a></li>
    <li><a href="https://www.linkedin.com/in/alexlegault/" target="_blank">Professional experience</a></li>
    <li>
        <a href="https://github.com/arlegault" target="_blank"
           onclick="gtag('event', 'click', {'event_category': 'outbound', 'event_label': 'external_link'});
                    setTimeout(function(){window.location.href='https://github.com/arlegault';}, 100);
                    return false;">
            Building tech debt in public
        </a>
    </li>
    <li><a href="side_projects.html">Side projects</a></li>
    <!-- <li><a href="consulting.html">Consulting</a></li> -->
</ul>

<div class = "center">
<h2>Where We Actually Are on the AI Curve</h2>

<p>Claude Code can write 100% of the code. It cannot write 100% of the company. That's the gap that nobody is talking about clearly enough.</p>

<p>The capability debate is nearly over. Anthropic engineers report that 70-90% of their code is AI-generated. They are quick to attribute the remaining 10% to most of the hard workloads.</p>

<p>Enterprise AI spending tripled in a single year. Models are legitimately good and getting better on a six-month cadence.</p>

<p>Yet if you look at Anthropic's job board right now (February of 2026), they're hiring recruiters, marketing leads, SEO specialists, event managers, and admin business partners.</p>

<p>The company building the most capable AI coding tool in the world still needs humans for everything that isn't code. That's not a capability problem. It's an organizational one.</p>

<h3>Three Curves in One Moment</h3>

<p>There are three curves happening simultaneously, and I think I've been making the mistake of looking at the wrong one.</p>

<h4>Curve One: Model Capability</h4>

<p>This one's exponential and getting the headlines. Enterprise AI spending hit $37 billion in 2025, up from $11 billion the year before.</p>

<p>Andreessen Horowitz reported that Anthropic's enterprise penetration went from 25% to 75% in under a year—customers running the most advanced models in production. Capabilities are really accelerating.</p>

<h4>Curve Two: Individual Power Users</h4>

<p>This is where things get interesting. At my fintech startup, our engineering team's monthly output is 3-4x since we embraced Claude Code. That curve is steepening. Half of that gain came within just the last two months.</p>

<p>AI applications are generating in two years the revenue that took traditional SaaS a decade. ChatGPT Enterprise saw weekly message volume jump 8x in 2025 alone. The people who use these tools daily are operating in a genuinely different reality than those who tried ChatGPT once and moved on.</p>

<h4>Curve Three: Organizations</h4>

<p>This one is slow. Most enterprises are still running pilots, debating procurement, fragmenting across three or four model providers without a coherent workflow. Innovation budgets went from 25% of all spend to 7%, which sounds like progress until you realize it mostly means AI moved from experiment to line item, not from line item to transformation.</p>

<p>As individuals and small teams, we're living on curve two. But most organizations are stuck on curve three. I think the mistake has been thinking that model capability was the big limiter; that might not be true anymore.</p>

<h3>The Bottleneck Moved</h3>

<p>A colleague made an observation that really stuck with me: "Anthropic is a company with brilliant engineers, massive compute, and an AI that theoretically could work 24 hours a day improving itself." They claim that Opus 4.6 is the first model that Claude itself helped to write. Meanwhile, a close friend of mine works at a financial services product team, and they're not shipping hundreds of features a week. Their team is certainly larger than ours. They have every advantage in this AI world, and yet the pace looks pretty normal.</p>

<p>My colleague's conclusion, which I think is very right: "The bottleneck is vision and product, not engineering capacity."</p>

<p>This has always been somewhat true. The myth that "more engineers equals more output" died a long time ago. Most organizations were already constrained by product clarity, prioritization, and decision speed before AI entered the picture. AI just made this embarrassingly visible. If you don't know what to build, AI helps you build the wrong thing faster. If your organization can't decide, AI gives you the ability to execute on all of your indecisions simultaneously. That's not a productivity gain; that's chaos.</p>

<h3>Why the Labs Look Like Magic</h3>

<p>The reason frontier labs seem to operate in a different universe is that they've optimized every part of the organization to absorb what AI can do. Clear decision-making. Tight feedback loops. High talent density. They're not just building better models—they're the only organizations structured to fully use them.</p>

<p>Everyone else is trying to fit exponential capability into linear organizational structures. The model can do the task; the organization can't yet absorb the model doing the task.</p>

<h3>The Real Shift</h3>

<p>We're entering intelligence abundance, but we're living in a clarity-scarce world. The labs are accelerating intelligence; everyone else still has to figure out what to do with it. A more powerful model does not automatically produce a more powerful organization. If you're an individual, you're probably already somewhere on curve two. The question is whether you can drag your organization from curve three toward curve two.</p>

<p>Speed—that's not an AI problem; that is a leadership problem.</p>

<h3>Where This Lands</h3>

<p>A colleague and I were texting about this recently. We're probably in the top 5% of AI adoption: using Claude Code daily, even outside of engineering, building product with it, watching our output multiply in real time. And we still can't fully automate the hardest parts of the business. If the frontier looks like this for us, imagine what it looks like for a 10,000-person enterprise that just started an AI committee.</p>

<p>There's a version of the future where all this gets automated in 5 years, and there's a version where early adopters are on a curve that's less steep than the hype suggests. I don't know which is right.</p>

<p>Here's what I keep coming back to: It doesn't actually matter which slope you're on. What matters is whether you're optimizing for the right constraint. For the first time in decades, execution speed isn't the bottleneck—clarity is. We can build anything now. The question is whether we know what we're building and why.</p>

<p>That means the companies winning this transition aren't the ones with the best AI tools. They're the ones that can decide fast, communicate clearly, and align their organization around fewer, better-defined outcomes. Intelligence is abundant now. Organizational clock speed is the new scarcity. The disruption is real, but the race isn't to adopt AI; it's to become the kind of organization that can absorb what AI already offers. That race has already started. Your customers won't wait for you to catch up.</p>

<h3>Stop Deliberating. The Window Is Closing.</h3>

<p>Enterprise AI spend tripled in a single year. The distribution is already splitting. The gap between companies on curve two and companies stuck on curve three is compounding daily. The question isn't whether you can train an AI; it's whether your organization can decide what to do with it.</p>

</div>
</body>
</html>
